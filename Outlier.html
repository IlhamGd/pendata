
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Outlier &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Outlier';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Local Outlier Factor (LOF)" href="LOF.html" />
    <link rel="prev" title="Data Understanding" href="Data_Understanding.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    MY DATA MINING INFORMATION PAGE
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Data_Understanding.html"><strong>Data Understanding</strong></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Outlier</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="LOF.html"><strong>Local Outlier Factor (LOF)</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FOutlier.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Outlier.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Outlier</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier-menggunakan-algoritma-k-nn"><strong>Deteksi Outlier Menggunakan Algoritma K-NN</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-deteksi-manual-outlier-dengan-k-nn-suhu"><strong>Contoh Deteksi Manual Outlier dengan K-NN (Suhu)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data"><strong>Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-deteksi-outlier"><strong>Langkah-Langkah Deteksi Outlier</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hitung-jarak-antar-titik"><strong>1. Hitung Jarak Antar Titik</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menentukan-outlier"><strong>2. Menentukan Outlier</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hitung-rata-rata-jarak-ke-k-tetangga-terdekat"><strong>3. Hitung Rata-rata jarak ke K tetangga terdekat</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>1. Hitung Jarak Antar Titik</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><strong>2. Menentukan Outlier</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>3. Hitung Rata-rata jarak ke K tetangga terdekat</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-mendeteksi-outlier-dengan-algoritma-k-nn-dengan-code"><strong>Langkah-langkah Mendeteksi Outlier Dengan Algoritma K-NN Dengan Code</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cek-koneksi-database-mysql">Cek koneksi Database MySQL</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cek-koneksi-database-postgresql">Cek koneksi Database PostgreSQL</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#merging-data"><strong>MERGING DATA</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-deteksi-outlier-dengan-algoritma-k-nn-euclidean-distance">Code Deteksi Outlier dengan Algoritma K-NN - Euclidean Distance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mencari-data-yang-diduga-outlier-menggunakan-localoutlierfactor"><strong>Mencari Data yang Diduga Outlier (menggunakan LocalOutlierFactor):</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fungsi-kode"><strong>Fungsi Kode</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mencari-data-yang-diduga-outlier-menggunakan-euclidean-distance"><strong>Mencari Data yang Diduga Outlier (menggunakan Euclidean Distance):</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-singkat-kode"><strong>Penjelasan Singkat Kode</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-bersih-dari-outlier"><strong>Data Bersih dari Outlier</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Penjelasan Singkat Kode</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#membandingkan-akurasi"><strong>Membandingkan Akurasi</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#persiapan-data-dan-encoding-kelas">✅ 1. Persiapan Data dan Encoding Kelas</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membuat-dan-melatih-model-knn-tanpa-menghapus-outlier">✅ 2. Membuat dan Melatih Model KNN (Tanpa Menghapus Outlier)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier-menggunakan-local-outlier-factor-lof">✅ 3. Deteksi Outlier Menggunakan Local Outlier Factor (LOF)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membersihkan-data-dari-outlier">✅ 4. Membersihkan Data dari Outlier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#melatih-ulang-model-knn-setelah-outlier-dihapus">✅ 5. Melatih Ulang Model KNN Setelah Outlier Dihapus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-dan-perbandingan-hasil">✅ 6. Evaluasi dan Perbandingan Hasil</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">📈 Kesimpulan:</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="outlier">
<h1><strong>Outlier</strong><a class="headerlink" href="#outlier" title="Link to this heading">#</a></h1>
<p>🔍 <strong>Apa itu Outlier?</strong><br />
Outlier adalah data yang memiliki nilai yang sangat berbeda dibandingkan dengan data lainnya dalam suatu dataset.</p>
<p>⚠ <strong>Mengapa Outlier Muncul?</strong><br />
Outlier bisa terjadi karena:<br />
✅ <strong>Kesalahan pengukuran</strong> –<br />
✅ <strong>Kesalahan input data</strong> –</p>
<p>✅ <strong>Fenomena yang jarang terjadi</strong> –</p>
<p>🧐 <strong>Mengapa Outlier Penting?</strong></p>
<ul class="simple">
<li><p>Karena Bisa menyebabkan hasil analisis yang bias.</p></li>
<li><p>Karena Dapat menunjukkan kejadian khusus yang perlu dianalisis lebih lanjut.</p></li>
<li><p>Karena Bisa membantu dalam deteksi anomali dalam sebuah data.</p></li>
</ul>
<section id="deteksi-outlier-menggunakan-algoritma-k-nn">
<h2><strong>Deteksi Outlier Menggunakan Algoritma K-NN</strong><a class="headerlink" href="#deteksi-outlier-menggunakan-algoritma-k-nn" title="Link to this heading">#</a></h2>
<hr class="docutils" />
<p><strong>1. Rumus Jarak Euclidean</strong><br />
Rumus <strong>jarak Euclidean</strong> untuk satu dimensi (misalnya suhu):</p>
<div class="math notranslate nohighlight">
\[
d(x_i, x_j) = |x_i - x_j|
\]</div>
<p>Di mana:</p>
<ul class="simple">
<li><p>( x_i ) = nilai suhu titik data ke-( i )</p></li>
<li><p>( x_j ) = nilai suhu titik data ke-( j )</p></li>
</ul>
<blockquote>
<div><p>🔹 Untuk <strong>multi-dimensi</strong>, gunakan rumus:<br />
$<span class="math notranslate nohighlight">\(
d(x_i, x_j) = \sqrt{\sum_{k=1}^{n} (x_{ik} - x_{jk})^2}
\)</span>$</p>
</div></blockquote>
<hr class="docutils" />
<p><strong>2. Rata-rata Jarak ke K Tetangga Terdekat</strong><br />
Setelah menghitung jarak ke semua titik, kita pilih <strong>K tetangga terdekat</strong> dan hitung <strong>rata-rata jaraknya</strong>:</p>
<div class="math notranslate nohighlight">
\[
\bar{d}_i = \frac{1}{K} \sum_{j=1}^{K} d(x_i, x_j)
\]</div>
<p>Di mana:</p>
<ul class="simple">
<li><p>( 𝑑𝑖 ) = rata-rata jarak ke <strong>K</strong> tetangga terdekat dari titik <strong>( x_i )</strong></p></li>
<li><p>( K ) = jumlah tetangga terdekat (misalnya <strong>K = 2</strong>)</p></li>
<li><p>( 𝑑(x_i, x_j) ) = jarak dari titik <strong>( x_i )</strong> ke <strong>tetangga ke-( j )</strong></p></li>
</ul>
<hr class="docutils" />
<p><strong>3. Menentukan Threshold Outlier</strong><br />
Gunakan <strong>mean + 2 * standar deviasi</strong> sebagai batas outlier:</p>
<div class="math notranslate nohighlight">
\[
Threshold = \mu + 2\sigma
\]</div>
<p>Di mana:</p>
<ul class="simple">
<li><p>( μ ) = <strong>mean</strong> dari semua (𝑑𝑖)</p></li>
<li><p>( σ ) = <strong>standar deviasi</strong> dari (𝑑𝑖)</p></li>
</ul>
<p>Jika <strong>rata-rata jarak suatu titik lebih besar dari threshold</strong>, maka titik tersebut <strong>outlier</strong>.</p>
</section>
<hr class="docutils" />
<section id="contoh-deteksi-manual-outlier-dengan-k-nn-suhu">
<h2><strong>Contoh Deteksi Manual Outlier dengan K-NN (Suhu)</strong><a class="headerlink" href="#contoh-deteksi-manual-outlier-dengan-k-nn-suhu" title="Link to this heading">#</a></h2>
<p>Metode <strong>K-Nearest Neighbors (K-NN)</strong> dapat digunakan untuk mendeteksi outlier dengan menghitung rata-rata jarak suatu titik data ke tetangga terdekatnya. Jika jaraknya jauh lebih besar dibandingkan data lain, maka titik tersebut bisa dianggap sebagai <strong>outlier</strong>.</p>
</section>
<hr class="docutils" />
<section id="data">
<h2><strong>Data</strong><a class="headerlink" href="#data" title="Link to this heading">#</a></h2>
<p>Misalkan kita memiliki data suhu harian selama 10 hari (dalam °C):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>X = [28, 29, 30, 31, 29, 32, 30, 28, 27, 40]
</pre></div>
</div>
<p>Saya menggunakan <strong>K = 2</strong> dan <strong>jarak Euclidean</strong> untuk mendeteksi outlier.</p>
</section>
<hr class="docutils" />
<section id="langkah-langkah-deteksi-outlier">
<h2><strong>Langkah-Langkah Deteksi Outlier</strong><a class="headerlink" href="#langkah-langkah-deteksi-outlier" title="Link to this heading">#</a></h2>
<section id="hitung-jarak-antar-titik">
<h3><strong>1. Hitung Jarak Antar Titik</strong><a class="headerlink" href="#hitung-jarak-antar-titik" title="Link to this heading">#</a></h3>
<p>Hitung Jarak Antara Setiap Titik Data</p>
<ul class="simple">
<li><p>Gunakan metrik Euclidean Distance (jarak antara dua titik dalam satu dimensi).</p></li>
</ul>
</section>
<section id="menentukan-outlier">
<h3><strong>2. Menentukan Outlier</strong><a class="headerlink" href="#menentukan-outlier" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Nilai K = 2 (dua tetangga terdekat).</p></li>
</ul>
</section>
<section id="hitung-rata-rata-jarak-ke-k-tetangga-terdekat">
<h3><strong>3. Hitung Rata-rata jarak ke K tetangga terdekat</strong><a class="headerlink" href="#hitung-rata-rata-jarak-ke-k-tetangga-terdekat" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Jika rata-rata jarak suatu titik jauh lebih besar dibandingkan dengan titik lain, maka titik tersebut dianggap sebagai outlier.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id1">
<h3><strong>1. Hitung Jarak Antar Titik</strong><a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Gunakan <strong>jarak Euclidean</strong> (selisih absolut antara dua titik dalam satu dimensi).</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Suhu (°C)</p></th>
<th class="head"><p>Tetangga 1</p></th>
<th class="head"><p>Jarak</p></th>
<th class="head"><p>Tetangga 2</p></th>
<th class="head"><p>Jarak</p></th>
<th class="head"><p>Rata-rata Jarak</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>28</p></td>
<td><p>27</p></td>
<td><p>1</p></td>
<td><p>29</p></td>
<td><p>1</p></td>
<td><p>(1+1)/2 = 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>29</p></td>
<td><p>28</p></td>
<td><p>1</p></td>
<td><p>30</p></td>
<td><p>1</p></td>
<td><p>(1+1)/2 = 1.0</p></td>
</tr>
<tr class="row-even"><td><p>30</p></td>
<td><p>29</p></td>
<td><p>1</p></td>
<td><p>31</p></td>
<td><p>1</p></td>
<td><p>(1+1)/2 = 1.0</p></td>
</tr>
<tr class="row-odd"><td><p>31</p></td>
<td><p>30</p></td>
<td><p>1</p></td>
<td><p>32</p></td>
<td><p>1</p></td>
<td><p>(1+1)/2 = 1.0</p></td>
</tr>
<tr class="row-even"><td><p>32</p></td>
<td><p>31</p></td>
<td><p>1</p></td>
<td><p>30</p></td>
<td><p>2</p></td>
<td><p>(1+2)/2 = 1.5</p></td>
</tr>
<tr class="row-odd"><td><p>27</p></td>
<td><p>28</p></td>
<td><p>1</p></td>
<td><p>29</p></td>
<td><p>2</p></td>
<td><p>(1+2)/2 = 1.5</p></td>
</tr>
<tr class="row-even"><td><p>40</p></td>
<td><p>32</p></td>
<td><p>8</p></td>
<td><p>31</p></td>
<td><p>9</p></td>
<td><p>(8+9)/2 = 8.5</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="id2">
<h3><strong>2. Menentukan Outlier</strong><a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Hampir semua titik memiliki rata-rata jarak <strong>1 - 1.5</strong>.</p></li>
<li><p><strong>Suhu 40°C memiliki rata-rata jarak ke tetangga sebesar 8.5</strong>, jauh lebih besar dibandingkan lainnya.</p></li>
<li><p>Maka, <strong>suhu 40°C adalah outlier</strong>.</p></li>
</ul>
</section>
<section id="id3">
<h3><strong>3. Hitung Rata-rata jarak ke K tetangga terdekat</strong><a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Rata-rata jarak kebanyakan nilai = 1.0 hingga 1.5</p></li>
<li><p>Suhu 40°C memiliki rata-rata jarak 8.5, yang jauh lebih besar dibandingkan yang lain.</p></li>
<li><p>Maka Metode <strong>K-NN Outlier</strong> mendeteksi bahwa <strong>40°C</strong> adalah outlier dalam data ini.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="langkah-langkah-mendeteksi-outlier-dengan-algoritma-k-nn-dengan-code">
<h2><strong>Langkah-langkah Mendeteksi Outlier Dengan Algoritma K-NN Dengan Code</strong><a class="headerlink" href="#langkah-langkah-mendeteksi-outlier-dengan-algoritma-k-nn-dengan-code" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymysql<span class="w"> </span>#Install<span class="w"> </span>library<span class="w"> </span>Python<span class="w"> </span>yang<span class="w"> </span>menjadi<span class="w"> </span>koneksi<span class="w"> </span>dan<span class="w"> </span>interaksi<span class="w"> </span>dengan<span class="w"> </span>database<span class="w"> </span>MySQL
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>psycopg2-binary<span class="w"> </span>#Install<span class="w"> </span>library<span class="w"> </span>Python<span class="w"> </span>yang<span class="w"> </span>menjadi<span class="w"> </span>koneksi<span class="w"> </span>dan<span class="w"> </span>interaksi<span class="w"> </span>dengan<span class="w"> </span>database<span class="w"> </span>MySQL
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.11/dist-packages (2.9.10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymysql<span class="w"> </span>pandas<span class="w"> </span>#instal<span class="w"> </span>PyMySQL<span class="w"> </span><span class="o">(</span>untuk<span class="w"> </span>koneksi<span class="w"> </span>MySQL<span class="o">)</span><span class="w"> </span>dan<span class="w"> </span>pandas<span class="w"> </span><span class="o">(</span>untuk<span class="w"> </span>manipulasi<span class="w"> </span>data<span class="w"> </span>dalam<span class="w"> </span>bentuk<span class="w"> </span>tabel<span class="o">)</span>.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: pymysql in /usr/local/lib/python3.11/dist-packages (1.1.1)
Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)
Requirement already satisfied: numpy&gt;=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span> <span class="c1">#koneksi database menggunakan SQLAlchemy.</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1">#Operasi numerik dan array multidimensi.</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span> <span class="c1">#Algoritma machine learning untuk pencarian tetangga terdekat (Nearest Neighbors).</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span> <span class="c1">#menampilkan data dalam format tabel</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span><span class="p">,</span> <span class="n">LocalOutlierFactor</span>
</pre></div>
</div>
</div>
</div>
<section id="cek-koneksi-database-mysql">
<h3>Cek koneksi Database MySQL<a class="headerlink" href="#cek-koneksi-database-mysql" title="Link to this heading">#</a></h3>
<p>Periksa apakah code berhasil import data dari Database MySQL</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pymysql</span>

<span class="c1"># Konfigurasi koneksi</span>
<span class="n">host</span> <span class="o">=</span> <span class="s2">&quot;mysqlpendata-ilhamalmafazt-dm.h.aivencloud.com&quot;</span>  <span class="c1"># Ganti host dengan host dari Aiven.io</span>
<span class="n">port</span> <span class="o">=</span> <span class="mi">19867</span>    <span class="c1"># Ganti posrt dengan posrt dari Aiven.io</span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span> <span class="c1"># Ganti user dengan user dari Aiven.io</span>
<span class="n">password</span> <span class="o">=</span> <span class="s2">&quot;AVNS_vnxDk9lOvZgFnuKlezN&quot;</span> <span class="c1"># Ganti password dengan password dari Aiven.io</span>
<span class="n">database</span> <span class="o">=</span> <span class="s2">&quot;defaultdb&quot;</span> <span class="c1"># Ganti database dengan database dari Aiven.io</span>

<span class="c1"># Buat koneksi</span>
<span class="n">mysql_conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="n">password</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
    <span class="n">ssl</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;ssl&#39;</span><span class="p">:</span> <span class="p">{}}</span>  <span class="c1"># Jika menggunakan SSL</span>
<span class="p">)</span>

<span class="c1">#menampilkan data</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">mysql_conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_sql.iris LIMIT 5;&quot;</span><span class="p">)</span>
<span class="n">tampil</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tampil</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">mysql_conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, &#39;Iris-setosa&#39;, 1.4, 0.2)
(2, &#39;Iris-setosa&#39;, 50.0, 20.0)
(3, &#39;Iris-setosa&#39;, 1.3, 0.2)
(4, &#39;Iris-setosa&#39;, 1.5, 0.2)
(5, &#39;Iris-setosa&#39;, 1.4, 0.2)
</pre></div>
</div>
</div>
</div>
</section>
<section id="cek-koneksi-database-postgresql">
<h3>Cek koneksi Database PostgreSQL<a class="headerlink" href="#cek-koneksi-database-postgresql" title="Link to this heading">#</a></h3>
<p>Memeriksa apakah code berhasil import data dari Database PostgreSQL</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>

<span class="c1"># Konfigurasi koneksi</span>
<span class="n">host</span> <span class="o">=</span> <span class="s2">&quot;postgrependata-ilhamalmafazt-dm.i.aivencloud.com&quot;</span>
<span class="n">port</span> <span class="o">=</span> <span class="mi">19867</span>
<span class="n">user</span> <span class="o">=</span> <span class="s2">&quot;avnadmin&quot;</span>
<span class="n">password</span> <span class="o">=</span> <span class="s2">&quot;AVNS_yBhPcNuf-iJ2fja4CBU&quot;</span>
<span class="n">database</span> <span class="o">=</span> <span class="s2">&quot;defaultdb&quot;</span>

<span class="c1"># Buat koneksi</span>
<span class="n">postgres_conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="n">port</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="n">password</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
    <span class="n">sslmode</span><span class="o">=</span><span class="s2">&quot;require&quot;</span>
<span class="p">)</span>
<span class="c1">#menampilkan data</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">postgres_conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM postgre.postgre LIMIT 5;&quot;</span><span class="p">)</span>
<span class="n">tampil</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">tampil</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">postgres_conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, &#39;Iris-setosa&#39;, 5.1, 3.5)
(3, &#39;Iris-setosa&#39;, 4.7, 3.2)
(4, &#39;Iris-setosa&#39;, 4.6, 3.1)
(5, &#39;Iris-setosa&#39;, 5.0, 3.6)
(6, &#39;Iris-setosa&#39;, 5.4, 3.9)
</pre></div>
</div>
</div>
</div>
</section>
<section id="merging-data">
<h3><strong>MERGING DATA</strong><a class="headerlink" href="#merging-data" title="Link to this heading">#</a></h3>
<p>Code ini bertujuan untuk menghubungkan dua database yang berbeda menjadi satu</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="c1"># Konfigurasi koneksi MySQL (Aiven.io)</span>
<span class="n">mysql_conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysqlpendata-ilhamalmafazt-dm.h.aivencloud.com&quot;</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="mi">19867</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_vnxDk9lOvZgFnuKlezN&quot;</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Konfigurasi koneksi PostgreSQL (Aiven.io)</span>
<span class="n">postgres_conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;postgrependata-ilhamalmafazt-dm.i.aivencloud.com&quot;</span><span class="p">,</span>
    <span class="n">port</span><span class="o">=</span><span class="mi">19867</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_yBhPcNuf-iJ2fja4CBU&quot;</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
    <span class="n">sslmode</span><span class="o">=</span><span class="s2">&quot;require&quot;</span>
<span class="p">)</span>

<span class="c1"># Ambil data dari MySQL</span>
<span class="n">mysql_query</span> <span class="o">=</span> <span class="s2">&quot;SELECT id, `petal length`, `petal width` FROM iris_sql.iris;&quot;</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">mysql_query</span><span class="p">,</span> <span class="n">mysql_conn</span><span class="p">)</span>

<span class="c1"># Ambil data dari PostgreSQL</span>
<span class="n">postgres_query</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM postgre.postgre;&quot;</span>
<span class="n">df_postgres</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">postgres_query</span><span class="p">,</span> <span class="n">postgres_conn</span><span class="p">)</span>

<span class="c1"># Tutup koneksi</span>
<span class="n">mysql_conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">postgres_conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Gabungkan data secara vertikal</span>
<span class="n">df_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_postgres</span><span class="p">,</span> <span class="n">df_mysql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>

<span class="c1"># Tampilkan data dalam format tabel yang lebih rapi</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">df_combined</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;grid&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ipython-input-7-42938d1cca3b&gt;:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df_mysql = pd.read_sql(mysql_query, mysql_conn)
&lt;ipython-input-7-42938d1cca3b&gt;:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  df_postgres = pd.read_sql(postgres_query, postgres_conn)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----+------+-----------------+----------------+---------------+----------------+---------------+
|     |   id | Class           |   sepal length |   sepal width |   petal length |   petal width |
+=====+======+=================+================+===============+================+===============+
|   0 |    1 | Iris-setosa     |            5.1 |           3.5 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   1 |    3 | Iris-setosa     |            4.7 |           3.2 |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   2 |    4 | Iris-setosa     |            4.6 |           3.1 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   3 |    5 | Iris-setosa     |            5   |           3.6 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   4 |    6 | Iris-setosa     |            5.4 |           3.9 |            1.7 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   5 |    7 | Iris-setosa     |            4.6 |           3.4 |            1.4 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   6 |    8 | Iris-setosa     |            5   |           3.4 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   7 |    9 | Iris-setosa     |            4.4 |           2.9 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   8 |   12 | Iris-setosa     |            4.8 |           3.4 |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   9 |   13 | Iris-setosa     |            4.8 |           3   |           14   |          10   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  10 |   14 | Iris-setosa     |            4.3 |           3   |            1.1 |           0.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  11 |   15 | Iris-setosa     |            5.8 |           4   |            1.2 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  12 |   16 | Iris-setosa     |            5.7 |           4.4 |            1.5 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  13 |   18 | Iris-setosa     |            5.1 |           3.5 |            1.4 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  14 |   19 | Iris-setosa     |            5.7 |           3.8 |           17   |          13   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  15 |   21 | Iris-setosa     |            5.4 |           3.4 |            1.7 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  16 |   22 | Iris-setosa     |            5.1 |           3.7 |           15   |           6   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  17 |   23 | Iris-setosa     |            4.6 |           3.6 |            1   |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  18 |   24 | Iris-setosa     |            5.1 |           3.3 |            1.7 |           0.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  19 |   26 | Iris-setosa     |            5   |           3   |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  20 |   27 | Iris-setosa     |            5   |           3.4 |            1.6 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  21 |   43 | Iris-setosa     |            4.4 |           3.2 |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  22 |   44 | Iris-setosa     |            5   |           3.5 |            1.6 |           0.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  23 |   45 | Iris-setosa     |            5.1 |           3.8 |            1.9 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  24 |   46 | Iris-setosa     |            4.8 |           3   |            1.4 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  25 |   47 | Iris-setosa     |            5.1 |           3.8 |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  26 |   48 | Iris-setosa     |            4.6 |           3.2 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  27 |   49 | Iris-setosa     |            5.3 |           3.7 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  28 |   50 | Iris-setosa     |            5   |           3.3 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  29 |   52 | Iris-versicolor |            6.4 |           3.2 |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  30 |   53 | Iris-versicolor |            6.9 |           3.1 |           40   |          15   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  31 |   54 | Iris-versicolor |            5.5 |           2.3 |            4   |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  32 |   55 | Iris-versicolor |            6.5 |           2.8 |            4.6 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  33 |   56 | Iris-versicolor |            5.7 |           2.8 |            4.5 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  34 |   57 | Iris-versicolor |            6.3 |           3.3 |            4.7 |           1.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  35 |   58 | Iris-versicolor |            4.9 |           2.4 |            3.3 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  36 |   59 | Iris-versicolor |            6.6 |           2.9 |            4.6 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  37 |   61 | Iris-versicolor |            5   |           2   |            3.5 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  38 |   62 | Iris-versicolor |            5.9 |           3   |            4.2 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  39 |   63 | Iris-versicolor |            6   |           2.2 |            4   |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  40 |   64 | Iris-versicolor |            6.1 |           2.9 |            4.7 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  41 |   65 | Iris-versicolor |            5.6 |           2.9 |            3.6 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  42 |   66 | Iris-versicolor |            6.7 |           3.1 |            4.4 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  43 |   68 | Iris-versicolor |            5.8 |           2.7 |            4.1 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  44 |   69 | Iris-versicolor |            6.2 |           2.2 |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  45 |   70 | Iris-versicolor |            5.6 |           2.5 |            3.9 |           1.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  46 |   71 | Iris-versicolor |            5.9 |           3.2 |            4.8 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  47 |   72 | Iris-versicolor |            6.1 |           2.8 |            4   |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  48 |   73 | Iris-versicolor |            6.3 |           2.5 |            4.9 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  49 |   74 | Iris-versicolor |            6.1 |           2.8 |            4.7 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  50 |   75 | Iris-versicolor |            6.4 |           2.9 |            4.3 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  51 |   76 | Iris-versicolor |            6.6 |           3   |            4.4 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  52 |   77 | Iris-versicolor |            6.8 |           2.8 |            4.8 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  53 |   78 | Iris-versicolor |            6.7 |           3   |            5   |           1.7 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  54 |   80 | Iris-versicolor |            5.7 |           2.6 |            3.5 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  55 |   81 | Iris-versicolor |            5.5 |           2.4 |            3.8 |           1.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  56 |   83 | Iris-versicolor |            5.8 |           2.7 |            3.9 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  57 |   84 | Iris-versicolor |            6   |           2.7 |            5.1 |           1.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  58 |   85 | Iris-versicolor |            5.4 |           3   |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  59 |   86 | Iris-versicolor |            6   |           3.4 |            4.5 |           1.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  60 |   87 | Iris-versicolor |            6.7 |           3.1 |            4.7 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  61 |   88 | Iris-versicolor |            6.3 |           2.3 |            4.4 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  62 |   89 | Iris-versicolor |            5.6 |           3   |            4.1 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  63 |   90 | Iris-versicolor |            5.5 |           2.5 |            4   |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  64 |   91 | Iris-versicolor |            5.5 |           2.6 |            4.4 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  65 |   92 | Iris-versicolor |            6.1 |           3   |            4.6 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  66 |   93 | Iris-versicolor |            5.8 |           2.6 |            4   |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  67 |   94 | Iris-versicolor |            5   |           2.3 |            3.3 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  68 |   95 | Iris-versicolor |            5.6 |           2.7 |            4.2 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  69 |   96 | Iris-versicolor |            5.7 |           3   |            4.2 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  70 |   97 | Iris-versicolor |            5.7 |           2.9 |            4.2 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  71 |   98 | Iris-versicolor |            6.2 |           2.9 |            4.3 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  72 |   99 | Iris-versicolor |            5.1 |           2.5 |            3   |           1.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  73 |  100 | Iris-versicolor |            5.7 |           2.8 |            4.1 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  74 |  101 | Iris-virginica  |            6.3 |           3.3 |            6   |           2.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  75 |  102 | Iris-virginica  |            5.8 |           2.7 |            5.1 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  76 |  103 | Iris-virginica  |            7.1 |           3   |            5.9 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  77 |  104 | Iris-virginica  |            6.3 |           2.9 |            5.6 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  78 |  105 | Iris-virginica  |            6.5 |           3   |            5.8 |           2.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  79 |  106 | Iris-virginica  |            7.6 |           3   |           66   |          21   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  80 |  107 | Iris-virginica  |            4.9 |           2.5 |            4.5 |           1.7 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  81 |  108 | Iris-virginica  |            7.3 |           2.9 |            6.3 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  82 |  109 | Iris-virginica  |            6.7 |           2.5 |            5.8 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  83 |  110 | Iris-virginica  |            7.2 |           3.6 |           61   |          25   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  84 |  111 | Iris-virginica  |            6.5 |           3.2 |            5.1 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  85 |  112 | Iris-virginica  |            6.4 |           2.7 |            5.3 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  86 |  113 | Iris-virginica  |            6.8 |           3   |            5.5 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  87 |  114 | Iris-virginica  |            5.7 |           2.5 |            5   |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  88 |  115 | Iris-virginica  |            5.8 |           2.8 |            5.1 |           2.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  89 |  116 | Iris-virginica  |            6.4 |           3.2 |            5.3 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  90 |  117 | Iris-virginica  |            6.5 |           3   |            5.5 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  91 |  118 | Iris-virginica  |            7.7 |           3.8 |           67   |          22   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  92 |  119 | Iris-virginica  |            7.7 |           2.6 |            6.9 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  93 |  120 | Iris-virginica  |            6   |           2.2 |            5   |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  94 |  121 | Iris-virginica  |            6.9 |           3.2 |            5.7 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  95 |  122 | Iris-virginica  |            5.6 |           2.8 |            4.9 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  96 |  123 | Iris-virginica  |            7.7 |           2.8 |            6.7 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  97 |  124 | Iris-virginica  |            6.3 |           2.7 |            4.9 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  98 |  125 | Iris-virginica  |            6.7 |           3.3 |            5.7 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  99 |  126 | Iris-virginica  |            7.2 |           3.2 |            6   |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 100 |  127 | Iris-virginica  |            6.2 |           2.8 |            4.8 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 101 |  128 | Iris-virginica  |            6.1 |           3   |           49   |          18   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 102 |  129 | Iris-virginica  |            6.4 |           2.8 |            5.6 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 103 |  131 | Iris-virginica  |            7.4 |           2.8 |            6.1 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 104 |  132 | Iris-virginica  |            7.9 |           3.8 |            6.4 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 105 |  134 | Iris-virginica  |            6.3 |           2.8 |           51   |          15   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 106 |  135 | Iris-virginica  |            6.1 |           2.6 |            5.6 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 107 |  136 | Iris-virginica  |            7.7 |           3   |            6.1 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 108 |  138 | Iris-virginica  |            6.4 |           3.1 |            5.5 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 109 |  139 | Iris-virginica  |            6   |           3   |           48   |          18   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 110 |  140 | Iris-virginica  |            6.9 |           3.1 |            5.4 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 111 |  141 | Iris-virginica  |            6.7 |           3.1 |            5.6 |           2.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 112 |  142 | Iris-virginica  |            6.9 |           3.1 |            5.1 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 113 |   28 | Iris-setosa     |            5.2 |           3.5 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 114 |   29 | Iris-setosa     |            5.2 |           4.3 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 115 |   30 | Iris-setosa     |            4.7 |           3.2 |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 116 |   31 | Iris-setosa     |            4.7 |           3.1 |           16   |          12   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 117 |   32 | Iris-setosa     |            5.5 |           4.4 |            1.5 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 118 |   33 | Iris-setosa     |            5.2 |           4.2 |            1.5 |           0.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 119 |   34 | Iris-setosa     |            5.5 |           4.2 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 120 |   35 | Iris-setosa     |            4.9 |           4.1 |           15   |           7   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 121 |   37 | Iris-setosa     |            5.5 |           3.5 |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 122 |   38 | Iris-setosa     |            4.9 |           3.1 |           15   |           8   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 123 |   39 | Iris-setosa     |            4.4 |           3   |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 124 |   41 | Iris-setosa     |            5   |           3.5 |            1.3 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 125 |   42 | Iris-setosa     |            4.5 |           2.3 |            1.3 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 126 |   10 | Iris-setosa     |           49   |          31   |            1.5 |           0.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 127 |   11 | Iris-setosa     |            5.4 |           3.7 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 128 |   17 | Iris-setosa     |           54   |          39   |            1.3 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 129 |   20 | Iris-setosa     |           51   |          38   |            1.5 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 130 |   25 | Iris-setosa     |           48   |          34   |            1.9 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 131 |   36 | Iris-setosa     |           50   |          32   |            1.2 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 132 |   51 | Iris-versicolor |           70   |          32   |            4.7 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 133 |   60 | Iris-versicolor |           52   |          27   |           39   |          14   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 134 |   67 | Iris-versicolor |           56   |          30   |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 135 |   82 | Iris-versicolor |           55   |          24   |            3.7 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 136 |  130 | Iris-virginica  |           72   |          30   |           58   |          16   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 137 |  133 | Iris-virginica  |           64   |          28   |            5.6 |           2.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 138 |  137 | Iris-virginica  |           63   |          34   |            5.6 |           2.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 139 |  143 | Iris-virginica  |            5.8 |           2.7 |            5.1 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 140 |  144 | Iris-virginica  |            6.8 |           3.2 |            5.9 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 141 |  146 | Iris-virginica  |            6.7 |           3   |            5.2 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 142 |  147 | Iris-virginica  |            6.3 |           2.5 |            5   |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 143 |  148 | Iris-virginica  |            6.5 |           3   |            5.2 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 144 |  150 | Iris-virginica  |            5.9 |           3   |            5.1 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 145 |    2 | Iris-setosa     |            4.9 |           3   |           50   |          20   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 146 |   40 | Iris-setosa     |            5.1 |           3.4 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 147 |   79 | Iris-versicolor |           60   |          29   |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 148 |  145 | Iris-virginica  |           67   |          33   |           57   |          25   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 149 |  149 | Iris-virginica  |           62   |          34   |            5.4 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
</pre></div>
</div>
</div>
</div>
</section>
<section id="code-deteksi-outlier-dengan-algoritma-k-nn-euclidean-distance">
<h3>Code Deteksi Outlier dengan Algoritma K-NN - Euclidean Distance<a class="headerlink" href="#code-deteksi-outlier-dengan-algoritma-k-nn-euclidean-distance" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span> <span class="c1">#import model Nearest Neighbors dari Library scikit-learn.</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="c1"># Menentukan fitur yang digunakan dalam perhitungan jarak</span>
<span class="n">feature_column</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">]</span>

<span class="c1"># Mengambil data fitur dari dataframe df_combined</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="n">feature_column</span><span class="p">]</span>

<span class="c1"># Mengisi nilai yang kosong (NaN) dengan rata-rata dari masing-masing kolom</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># jumlah tetangga terdekat (k)</span>
<span class="n">nilai_k</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># model Nearest Neighbors dengan matriks Euclidean</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">nilai_k</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Menghitung jarak Euclidean terdekat</span>
<span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Membuat dataframe baru untuk menyimpan fitur dan jarak Euclidean rata-rata</span>
<span class="n">df_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_column</span><span class="p">)</span>

<span class="c1"># rata-rata jarak ke tetangga terdekat</span>
<span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">distances</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hasil dari perhitungan jarak menggunakan Euclidean&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">df_features</span><span class="p">[[</span><span class="s2">&quot;sepal length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal width&quot;</span><span class="p">,</span> <span class="s2">&quot;petal length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal width&quot;</span><span class="p">,</span> <span class="s2">&quot;euclidean_distance&quot;</span><span class="p">]],</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hasil dari perhitungan jarak menggunakan Euclidean
+-----+----------------+---------------+----------------+---------------+----------------------+
|     |   sepal length |   sepal width |   petal length |   petal width |   euclidean_distance |
+=====+================+===============+================+===============+======================+
|   0 |            5.1 |           3.5 |            1.4 |           0.2 |             0.104853 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   1 |            4.7 |           3.2 |            1.3 |           0.2 |             0.183104 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   2 |            4.6 |           3.1 |            1.5 |           0.2 |             0.16483  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   3 |            5   |           3.6 |            1.4 |           0.2 |             0.142288 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   4 |            5.4 |           3.9 |            1.7 |           0.4 |             0.293686 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   5 |            4.6 |           3.4 |            1.4 |           0.3 |             0.220882 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   6 |            5   |           3.4 |            1.5 |           0.2 |             0.122925 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   7 |            4.4 |           2.9 |            1.4 |           0.2 |             0.220812 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   8 |            4.8 |           3.4 |            1.6 |           0.2 |             0.206011 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|   9 |            4.8 |           3   |           14   |          10   |             2.52299  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  10 |            4.3 |           3   |            1.1 |           0.1 |             0.277434 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  11 |            5.8 |           4   |            1.2 |           0.2 |             0.426947 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  12 |            5.7 |           4.4 |            1.5 |           0.4 |             0.333011 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  13 |            5.1 |           3.5 |            1.4 |           0.3 |             0.117566 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  14 |            5.7 |           3.8 |           17   |          13   |             3.62989  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  15 |            5.4 |           3.4 |            1.7 |           0.2 |             0.279055 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  16 |            5.1 |           3.7 |           15   |           6   |             2.70225  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  17 |            4.6 |           3.6 |            1   |           0.2 |             0.405258 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  18 |            5.1 |           3.3 |            1.7 |           0.5 |             0.245208 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  19 |            5   |           3   |            1.6 |           0.2 |             0.286684 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  20 |            5   |           3.4 |            1.6 |           0.4 |             0.178433 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  21 |            4.4 |           3.2 |            1.3 |           0.2 |             0.204721 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  22 |            5   |           3.5 |            1.6 |           0.6 |             0.257322 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  23 |            5.1 |           3.8 |            1.9 |           0.4 |             0.342861 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  24 |            4.8 |           3   |            1.4 |           0.3 |             0.22583  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  25 |            5.1 |           3.8 |            1.6 |           0.2 |             0.241655 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  26 |            4.6 |           3.2 |            1.4 |           0.2 |             0.146011 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  27 |            5.3 |           3.7 |            1.5 |           0.2 |             0.173711 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  28 |            5   |           3.3 |            1.4 |           0.2 |             0.156636 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  29 |            6.4 |           3.2 |            4.5 |           1.5 |             0.260276 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  30 |            6.9 |           3.1 |           40   |          15   |             8.09832  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  31 |            5.5 |           2.3 |            4   |           1.3 |             0.250424 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  32 |            6.5 |           2.8 |            4.6 |           1.5 |             0.261902 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  33 |            5.7 |           2.8 |            4.5 |           1.3 |             0.267657 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  34 |            6.3 |           3.3 |            4.7 |           1.6 |             0.304253 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  35 |            4.9 |           2.4 |            3.3 |           1   |             0.354876 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  36 |            6.6 |           2.9 |            4.6 |           1.3 |             0.224471 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  37 |            5   |           2   |            3.5 |           1   |             0.450813 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  38 |            5.9 |           3   |            4.2 |           1.5 |             0.279055 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  39 |            6   |           2.2 |            4   |           1   |             0.428066 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  40 |            6.1 |           2.9 |            4.7 |           1.4 |             0.245036 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  41 |            5.6 |           2.9 |            3.6 |           1.3 |             0.380199 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  42 |            6.7 |           3.1 |            4.4 |           1.4 |             0.224057 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  43 |            5.8 |           2.7 |            4.1 |           1   |             0.244002 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  44 |            6.2 |           2.2 |            4.5 |           1.5 |             0.398245 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  45 |            5.6 |           2.5 |            3.9 |           1.1 |             0.196546 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  46 |            5.9 |           3.2 |            4.8 |           1.8 |             0.350772 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  47 |            6.1 |           2.8 |            4   |           1.3 |             0.290448 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  48 |            6.3 |           2.5 |            4.9 |           1.5 |             0.326604 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  49 |            6.1 |           2.8 |            4.7 |           1.2 |             0.283551 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  50 |            6.4 |           2.9 |            4.3 |           1.3 |             0.242486 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  51 |            6.6 |           3   |            4.4 |           1.4 |             0.193435 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  52 |            6.8 |           2.8 |            4.8 |           1.4 |             0.292214 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  53 |            6.7 |           3   |            5   |           1.7 |             0.327001 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  54 |            5.7 |           2.6 |            3.5 |           1   |             0.355282 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  55 |            5.5 |           2.4 |            3.8 |           1.1 |             0.239494 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  56 |            5.8 |           2.7 |            3.9 |           1.2 |             0.197768 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  57 |            6   |           2.7 |            5.1 |           1.6 |             0.301517 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  58 |            5.4 |           3   |            4.5 |           1.5 |             0.378339 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  59 |            6   |           3.4 |            4.5 |           1.6 |             0.345146 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  60 |            6.7 |           3.1 |            4.7 |           1.5 |             0.265055 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  61 |            6.3 |           2.3 |            4.4 |           1.3 |             0.407783 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  62 |            5.6 |           3   |            4.1 |           1.3 |             0.177249 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  63 |            5.5 |           2.5 |            4   |           1.3 |             0.20899  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  64 |            5.5 |           2.6 |            4.4 |           1.2 |             0.285866 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  65 |            6.1 |           3   |            4.6 |           1.4 |             0.235026 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  66 |            5.8 |           2.6 |            4   |           1.2 |             0.183104 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  67 |            5   |           2.3 |            3.3 |           1   |             0.322077 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  68 |            5.6 |           2.7 |            4.2 |           1.3 |             0.192277 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  69 |            5.7 |           3   |            4.2 |           1.2 |             0.178248 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  70 |            5.7 |           2.9 |            4.2 |           1.3 |             0.135931 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  71 |            6.2 |           2.9 |            4.3 |           1.3 |             0.253074 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  72 |            5.1 |           2.5 |            3   |           1.1 |             0.457886 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  73 |            5.7 |           2.8 |            4.1 |           1.3 |             0.156636 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  74 |            6.3 |           3.3 |            6   |           2.5 |             0.463053 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  75 |            5.8 |           2.7 |            5.1 |           1.9 |             0.182493 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  76 |            7.1 |           3   |            5.9 |           2.1 |             0.331573 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  77 |            6.3 |           2.9 |            5.6 |           1.8 |             0.241772 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  78 |            6.5 |           3   |            5.8 |           2.2 |             0.290276 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  79 |            7.6 |           3   |           66   |          21   |             8.10749  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  80 |            4.9 |           2.5 |            4.5 |           1.7 |             0.657849 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  81 |            7.3 |           2.9 |            6.3 |           1.8 |             0.371293 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  82 |            6.7 |           2.5 |            5.8 |           1.8 |             0.479544 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  83 |            7.2 |           3.6 |           61   |          25   |             7.88737  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  84 |            6.5 |           3.2 |            5.1 |           2   |             0.28926  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  85 |            6.4 |           2.7 |            5.3 |           1.9 |             0.296408 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  86 |            6.8 |           3   |            5.5 |           2.1 |             0.250867 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  87 |            5.7 |           2.5 |            5   |           2   |             0.276086 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  88 |            5.8 |           2.8 |            5.1 |           2.4 |             0.405863 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  89 |            6.4 |           3.2 |            5.3 |           2.3 |             0.316569 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  90 |            6.5 |           3   |            5.5 |           1.8 |             0.226845 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  91 |            7.7 |           3.8 |           67   |          22   |             8.65393  |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  92 |            7.7 |           2.6 |            6.9 |           2.3 |             0.639693 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  93 |            6   |           2.2 |            5   |           1.5 |             0.415423 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  94 |            6.9 |           3.2 |            5.7 |           2.3 |             0.229747 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  95 |            5.6 |           2.8 |            4.9 |           2   |             0.284475 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  96 |            7.7 |           2.8 |            6.7 |           2   |             0.479764 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  97 |            6.3 |           2.7 |            4.9 |           1.8 |             0.238204 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  98 |            6.7 |           3.3 |            5.7 |           2.1 |             0.272912 |
+-----+----------------+---------------+----------------+---------------+----------------------+
|  99 |            7.2 |           3.2 |            6   |           1.8 |             0.388061 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 100 |            6.2 |           2.8 |            4.8 |           1.8 |             0.284131 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 101 |            6.1 |           3   |           49   |          18   |             3.33607  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 102 |            6.4 |           2.8 |            5.6 |           2.1 |             0.281871 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 103 |            7.4 |           2.8 |            6.1 |           1.9 |             0.346078 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 104 |            7.9 |           3.8 |            6.4 |           2   |             0.823922 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 105 |            6.3 |           2.8 |           51   |          15   |             4.8373   |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 106 |            6.1 |           2.6 |            5.6 |           1.4 |             0.491724 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 107 |            7.7 |           3   |            6.1 |           2.3 |             0.516015 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 108 |            6.4 |           3.1 |            5.5 |           1.8 |             0.241912 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 109 |            6   |           3   |           48   |          18   |             3.37792  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 110 |            6.9 |           3.1 |            5.4 |           2.1 |             0.253696 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 111 |            6.7 |           3.1 |            5.6 |           2.4 |             0.26359  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 112 |            6.9 |           3.1 |            5.1 |           2.3 |             0.31689  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 113 |            5.2 |           3.5 |            1.5 |           0.2 |             0.135931 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 114 |            5.2 |           4.3 |            1.4 |           0.2 |             0.284891 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 115 |            4.7 |           3.2 |            1.6 |           0.2 |             0.184084 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 116 |            4.7 |           3.1 |           16   |          12   |             2.80561  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 117 |            5.5 |           4.4 |            1.5 |           0.4 |             0.271268 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 118 |            5.2 |           4.2 |            1.5 |           0.1 |             0.28196  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 119 |            5.5 |           4.2 |            1.4 |           0.2 |             0.261689 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 120 |            4.9 |           4.1 |           15   |           7   |             2.21186  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 121 |            5.5 |           3.5 |            1.3 |           0.2 |             0.283855 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 122 |            4.9 |           3.1 |           15   |           8   |             1.97606  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 123 |            4.4 |           3   |            1.3 |           0.2 |             0.177274 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 124 |            5   |           3.5 |            1.3 |           0.3 |             0.146556 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 125 |            4.5 |           2.3 |            1.3 |           0.3 |             0.577556 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 126 |           49   |          31   |            1.5 |           0.1 |             3.94575  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 127 |            5.4 |           3.7 |            1.5 |           0.2 |             0.202901 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 128 |           54   |          39   |            1.3 |           0.4 |             5.70244  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 129 |           51   |          38   |            1.5 |           0.3 |             4.3122   |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 130 |           48   |          34   |            1.9 |           0.2 |             3.79112  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 131 |           50   |          32   |            1.2 |           0.2 |             3.54102  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 132 |           70   |          32   |            4.7 |           1.4 |             6.69634  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 133 |           52   |          27   |           39   |          14   |            25.7678   |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 134 |           56   |          30   |            4.5 |           1.5 |             4.96815  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 135 |           55   |          24   |            3.7 |           1   |             6.52052  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 136 |           72   |          30   |           58   |          16   |            29.6853   |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 137 |           64   |          28   |            5.6 |           2.2 |             4.80997  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 138 |           63   |          34   |            5.6 |           2.4 |             4.10316  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 139 |            5.8 |           2.7 |            5.1 |           1.9 |             0.182493 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 140 |            6.8 |           3.2 |            5.9 |           2.3 |             0.254709 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 141 |            6.7 |           3   |            5.2 |           2.3 |             0.268045 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 142 |            6.3 |           2.5 |            5   |           1.9 |             0.283745 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 143 |            6.5 |           3   |            5.2 |           2   |             0.258225 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 144 |            5.9 |           3   |            5.1 |           1.8 |             0.279609 |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 145 |            4.9 |           3   |           50   |          20   |             4.44445  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 146 |            5.1 |           3.4 |            1.5 |           0.2 |             0.11121  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 147 |           60   |          29   |            4.5 |           1.5 |             3.99345  |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 148 |           67   |          33   |           57   |          25   |            30.0345   |
+-----+----------------+---------------+----------------+---------------+----------------------+
| 149 |           62   |          34   |            5.4 |           2.3 |             4.03646  |
+-----+----------------+---------------+----------------+---------------+----------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q1</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">Q3</span> <span class="o">=</span> <span class="n">df_features</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>

<span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

<span class="c1"># Menentukan batas bawah dan atas</span>
<span class="n">batas_bawah</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
<span class="n">batas_atas</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>

<span class="c1"># Ambil data outlier</span>
<span class="c1"># Merge df_features with df_combined to have all columns for outlier analysis</span>
<span class="n">df_combined</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_combined</span><span class="p">,</span> <span class="n">df_features</span><span class="p">[[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]],</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[(</span><span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">batas_bawah</span><span class="p">)</span> <span class="o">|</span>
                      <span class="p">(</span><span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">batas_atas</span><span class="p">)]</span>
<span class="n">outlier_terbesar</span> <span class="o">=</span> <span class="n">outliers</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">outliers</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Outlier Terbesar:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">outlier_terbesar</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Outlier Terbesar:
+-----+------+----------------+----------------+---------------+----------------+---------------+----------------------+
|     |   id | Class          |   sepal length |   sepal width |   petal length |   petal width |   euclidean_distance |
+=====+======+================+================+===============+================+===============+======================+
| 148 |  145 | Iris-virginica |             67 |            33 |             57 |            25 |              30.0345 |
+-----+------+----------------+----------------+---------------+----------------+---------------+----------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Membuat figure dengan ukuran 10x6</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Scatter plot Euclidean Distance dengan warna merah untuk outlier</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_combined</span><span class="p">)),</span> <span class="n">y</span><span class="o">=</span><span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">],</span>
                <span class="n">hue</span><span class="o">=</span><span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">batas_atas</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="p">{</span><span class="kc">False</span><span class="p">:</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">})</span>

<span class="c1"># garis batas bawah dan atas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">batas_atas</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Batas Atas (Outlier)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">batas_bawah</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Batas Bawah (Outlier)&quot;</span><span class="p">)</span>

<span class="c1"># judul, dan label sumbu</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter Plot Euclidean Distance (Menentukan Outlier)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index Data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Euclidean Distance&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/50cbc9948674b835f828b3641681cf37fb8edea5aa0853474e5e176cb9f7cdf1.png" src="_images/50cbc9948674b835f828b3641681cf37fb8edea5aa0853474e5e176cb9f7cdf1.png" />
</div>
</div>
<ul class="simple">
<li><p>Dapat dilihat bahwa mem-visualisasikan data sangat efektif untuk mendeteksi Outlier</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from sklearn.neighbors import LocalOutlierFactor</span>
<span class="c1"># from sklearn.impute import SimpleImputer</span>

<span class="c1"># # Create an imputer to replace NaN values with the mean</span>
<span class="c1"># imputer = SimpleImputer(strategy=&#39;mean&#39;)</span>

<span class="c1"># # Fit the imputer on your data and transform it</span>
<span class="c1"># # Replace result_df with df_combined</span>
<span class="c1"># X_imputed = imputer.fit_transform(df_combined[[&#39;petal length&#39;, &#39;petal width&#39;, &#39;sepal length&#39;, &#39;sepal width&#39;]]) # Updated line</span>

<span class="c1"># # Now, use the imputed data for LocalOutlierFactor</span>
<span class="c1"># clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)</span>
<span class="c1"># # Replace result_df with df_combined</span>
<span class="c1"># y_pred = clf.fit_predict(X_imputed) # Updated line</span>

<span class="c1"># # ... (rest of your code)</span>

<span class="c1"># # Instead of comparing against ground_truth (which has different size),</span>
<span class="c1"># # evaluate using the model&#39;s inbuilt outlier prediction</span>
<span class="c1"># outlier_index = np.where(y_pred == -1) # Outlier are labeled -1 by LOF</span>

<span class="c1"># # Print outliers</span>
<span class="c1"># print(&quot;Data yang diduga outlier (menggunakan LocalOutlierFactor):&quot;)</span>
<span class="c1"># # Replace result_df with df_combined</span>
<span class="c1"># print(df_combined.iloc[outlier_index]) # Updated line</span>
<span class="c1"># print (y_pred)</span>
<span class="c1"># data = list(enumerate(y_pred))</span>
<span class="c1"># print(tabulate(data, headers=[&quot;Index&quot;, &quot;y_pred&quot;], tablefmt=&quot;grid&quot;))</span>
<span class="c1"># # Replace result_df with df_combined</span>
<span class="c1"># print(f&quot;Jumlah total data: {len(df_combined)}&quot;) # Updated line</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># cfl = LocalOutlierFactor(n_neighbors=20, contamination=0.1)</span>
<span class="c1"># y_pred = cfl.fit_predict(X_imputed)</span>

<span class="c1"># df_combined[&#39;y_pred&#39;] = y_pred</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from sklearn.datasets import load_iris</span>
<span class="c1"># from sklearn.model_selection import train_test_split</span>

<span class="c1"># iris = load_iris(as_frame=True)</span>
<span class="c1"># X = iris.data[[&quot;sepal length (cm)&quot;, &quot;sepal width (cm)&quot;]]</span>
<span class="c1"># y = iris.target</span>
<span class="c1"># X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="mencari-data-yang-diduga-outlier-menggunakan-localoutlierfactor">
<h2><strong>Mencari Data yang Diduga Outlier (menggunakan LocalOutlierFactor):</strong><a class="headerlink" href="#mencari-data-yang-diduga-outlier-menggunakan-localoutlierfactor" title="Link to this heading">#</a></h2>
<section id="fungsi-kode">
<h3><strong>Fungsi Kode</strong><a class="headerlink" href="#fungsi-kode" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>✅ Membersihkan data dari <strong>outlier</strong></p></li>
<li><p>✅ Menggunakan <strong>Local Outlier Factor (LOF)</strong> sebagai algoritma deteksi</p></li>
<li><p>✅ Menyediakan dataset <strong>bersih</strong> untuk proses <strong>analisis</strong> atau <strong>machine learning</strong> berikutnya</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>

<span class="c1"># Contoh DataFrame (pastikan df_combined sudah tersedia di kode utama)</span>
<span class="c1"># df_combined = pd.read_csv(&quot;your_data.csv&quot;) # Uncomment jika membaca dari file</span>

<span class="c1"># Pastikan kolom yang digunakan tersedia di df_combined</span>
<span class="n">selected_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">]</span>

<span class="c1"># Mengatasi missing values dengan imputasi (mean)</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">X_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_combined</span><span class="p">[</span><span class="n">selected_columns</span><span class="p">])</span>

<span class="c1"># Menerapkan Local Outlier Factor (LOF)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_imputed</span><span class="p">)</span>

<span class="c1"># Menentukan indeks data outlier</span>
<span class="n">outlier_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Indeks data yang terdeteksi sebagai outlier</span>

<span class="c1"># Menampilkan data yang diduga outlier</span>
<span class="n">columns_to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">]</span>
<span class="n">df_combined</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns_to_drop</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_combined</span><span class="o">.</span><span class="n">columns</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">df_combined</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">outlier_index</span><span class="p">])</span>

<span class="c1"># Menampilkan hasil prediksi LOF</span>
<span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Hasil prediksi LOF (-1 = outlier):&quot;</span><span class="p">)</span>
<span class="c1"># print(tabulate(data, headers=[&quot;Index&quot;, &quot;y_pred&quot;], tablefmt=&quot;grid&quot;))</span>

<span class="c1"># Menyaring hanya data yang bukan outlier (y_pred == 1)</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_combined</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Menampilkan jumlah data sebelum dan sesudah penyaringan</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah total data sebelum filtering: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_combined</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah total data setelah filtering: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      id            Class  sepal length  sepal width  petal length  \
79   106   Iris-virginica           7.6          3.0          66.0   
91   118   Iris-virginica           7.7          3.8          67.0   
126   10      Iris-setosa          49.0         31.0           1.5   
128   17      Iris-setosa          54.0         39.0           1.3   
129   20      Iris-setosa          51.0         38.0           1.5   
130   25      Iris-setosa          48.0         34.0           1.9   
131   36      Iris-setosa          50.0         32.0           1.2   
132   51  Iris-versicolor          70.0         32.0           4.7   
134   67  Iris-versicolor          56.0         30.0           4.5   
135   82  Iris-versicolor          55.0         24.0           3.7   
137  133   Iris-virginica          64.0         28.0           5.6   
138  137   Iris-virginica          63.0         34.0           5.6   
145    2      Iris-setosa           4.9          3.0          50.0   
147   79  Iris-versicolor          60.0         29.0           4.5   
149  149   Iris-virginica          62.0         34.0           5.4   

     petal width  euclidean_distance  
79          21.0            8.107486  
91          22.0            8.653927  
126          0.1            3.945745  
128          0.4            5.702443  
129          0.3            4.312196  
130          0.2            3.791118  
131          0.2            3.541016  
132          1.4            6.696338  
134          1.5            4.968150  
135          1.0            6.520516  
137          2.2            4.809971  
138          2.4            4.103158  
145         20.0            4.444455  
147          1.5            3.993455  
149          2.3            4.036461  

Hasil prediksi LOF (-1 = outlier):

Jumlah total data sebelum filtering: 150
Jumlah total data setelah filtering: 135
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="mencari-data-yang-diduga-outlier-menggunakan-euclidean-distance">
<h2><strong>Mencari Data yang Diduga Outlier (menggunakan Euclidean Distance):</strong><a class="headerlink" href="#mencari-data-yang-diduga-outlier-menggunakan-euclidean-distance" title="Link to this heading">#</a></h2>
<section id="penjelasan-singkat-kode">
<h3><strong>Penjelasan Singkat Kode</strong><a class="headerlink" href="#penjelasan-singkat-kode" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>✅ Mendeteksi data <strong>outlier</strong> menggunakan <strong>Local Outlier Factor (LOF)</strong></p></li>
<li><p>✅ Menentukan data mana yang terdeteksi sebagai <strong>outlier</strong></p></li>
<li><p>✅ Menampilkan <strong>data outlier</strong></p></li>
<li><p>✅ Menghitung dan menampilkan <strong>total outlier</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menentukan fitur yang digunakan dalam perhitungan jarak</span>
<span class="n">feature_column</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">]</span>


<span class="c1"># Deteksi Outlier dengan LOF untuk perbandingan</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">y_lof</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">outliers_lof</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="n">y_lof</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># -1 berarti outlier di LOF</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">outliers_lof</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total Outlier (LOF 10%): </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">outliers_lof</span><span class="p">)</span><span class="si">}</span><span class="s2"> dari </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_combined</span><span class="p">)</span><span class="si">}</span><span class="s2"> data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
|     |   id | Class           |   sepal length |   sepal width |   petal length |   petal width |   euclidean_distance |
+=====+======+=================+================+===============+================+===============+======================+
|  79 |  106 | Iris-virginica  |            7.6 |           3   |           66   |          21   |              8.10749 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
|  91 |  118 | Iris-virginica  |            7.7 |           3.8 |           67   |          22   |              8.65393 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 126 |   10 | Iris-setosa     |           49   |          31   |            1.5 |           0.1 |              3.94575 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 128 |   17 | Iris-setosa     |           54   |          39   |            1.3 |           0.4 |              5.70244 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 129 |   20 | Iris-setosa     |           51   |          38   |            1.5 |           0.3 |              4.3122  |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 130 |   25 | Iris-setosa     |           48   |          34   |            1.9 |           0.2 |              3.79112 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 131 |   36 | Iris-setosa     |           50   |          32   |            1.2 |           0.2 |              3.54102 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 132 |   51 | Iris-versicolor |           70   |          32   |            4.7 |           1.4 |              6.69634 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 134 |   67 | Iris-versicolor |           56   |          30   |            4.5 |           1.5 |              4.96815 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 135 |   82 | Iris-versicolor |           55   |          24   |            3.7 |           1   |              6.52052 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 137 |  133 | Iris-virginica  |           64   |          28   |            5.6 |           2.2 |              4.80997 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 138 |  137 | Iris-virginica  |           63   |          34   |            5.6 |           2.4 |              4.10316 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 145 |    2 | Iris-setosa     |            4.9 |           3   |           50   |          20   |              4.44445 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 147 |   79 | Iris-versicolor |           60   |          29   |            4.5 |           1.5 |              3.99345 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
| 149 |  149 | Iris-virginica  |           62   |          34   |            5.4 |           2.3 |              4.03646 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+----------------------+
Total Outlier (LOF 10%): 15 dari 150 data
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-bersih-dari-outlier">
<h2><strong>Data Bersih dari Outlier</strong><a class="headerlink" href="#data-bersih-dari-outlier" title="Link to this heading">#</a></h2>
<section id="id4">
<h3><strong>Penjelasan Singkat Kode</strong><a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>✅ <strong>Mengisi missing value</strong> pada dataset dengan rata-rata tiap kolom</p></li>
<li><p>✅ <strong>Menghapus outlier</strong>, sehingga hanya menyisakan data <strong>bersih (inlier)</strong></p></li>
<li><p>✅ <strong>Menampilkan tabel data akhir</strong> dan menghitung <strong>total data awal</strong>, <strong>jumlah outlier</strong>, serta <strong>total data bersih</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="c1"># Persiapan Data</span>
<span class="n">feature_column</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="n">feature_column</span><span class="p">]</span>

<span class="c1"># Mengisi missing value dengan rata-rata</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">X_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Deteksi Outlier Menggunakan LOF</span>
<span class="n">contamination_value</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Sesuaikan jika ingin lebih banyak/makin sedikit outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="n">contamination_value</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_imputed</span><span class="p">)</span>

<span class="c1"># Tambahkan hasil prediksi ke DataFrame</span>
<span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span>

<span class="c1"># Data Statistik Outlier</span>
<span class="n">total_data_awal</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_combined</span><span class="p">)</span>
<span class="n">total_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Filter hanya inlier (outlier == 1)</span>
<span class="n">df_clean</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="n">df_combined</span><span class="p">[</span><span class="s1">&#39;outlier&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">total_bersih</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_clean</span><span class="p">)</span>

<span class="c1"># Hapus Kolom yang Tidak Diperlukan</span>
<span class="n">columns_to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;euclidean_distance&#39;</span><span class="p">,</span> <span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="s1">&#39;outlier&#39;</span><span class="p">]</span>
<span class="n">df_clean</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">columns_to_drop</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df_clean</span><span class="o">.</span><span class="n">columns</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Menampilkan Data Bersih</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Bersih Setelah Menghapus Outlier (Metode LOF)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">df_clean</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">&quot;keys&quot;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;grid&quot;</span><span class="p">))</span>

<span class="c1"># Menampilkan Total Data</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">==============================&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total Data Awal     : </span><span class="si">{</span><span class="n">total_data_awal</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total Outlier       : </span><span class="si">{</span><span class="n">total_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total Data Bersih   : </span><span class="si">{</span><span class="n">total_bersih</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;==============================&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data Bersih Setelah Menghapus Outlier (Metode LOF)
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|     |   id | Class           |   sepal length |   sepal width |   petal length |   petal width |
+=====+======+=================+================+===============+================+===============+
|   0 |    1 | Iris-setosa     |            5.1 |           3.5 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   1 |    3 | Iris-setosa     |            4.7 |           3.2 |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   2 |    4 | Iris-setosa     |            4.6 |           3.1 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   3 |    5 | Iris-setosa     |            5   |           3.6 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   4 |    6 | Iris-setosa     |            5.4 |           3.9 |            1.7 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   5 |    7 | Iris-setosa     |            4.6 |           3.4 |            1.4 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   6 |    8 | Iris-setosa     |            5   |           3.4 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   7 |    9 | Iris-setosa     |            4.4 |           2.9 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   8 |   12 | Iris-setosa     |            4.8 |           3.4 |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|   9 |   13 | Iris-setosa     |            4.8 |           3   |           14   |          10   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  10 |   14 | Iris-setosa     |            4.3 |           3   |            1.1 |           0.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  11 |   15 | Iris-setosa     |            5.8 |           4   |            1.2 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  12 |   16 | Iris-setosa     |            5.7 |           4.4 |            1.5 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  13 |   18 | Iris-setosa     |            5.1 |           3.5 |            1.4 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  14 |   19 | Iris-setosa     |            5.7 |           3.8 |           17   |          13   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  15 |   21 | Iris-setosa     |            5.4 |           3.4 |            1.7 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  16 |   22 | Iris-setosa     |            5.1 |           3.7 |           15   |           6   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  17 |   23 | Iris-setosa     |            4.6 |           3.6 |            1   |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  18 |   24 | Iris-setosa     |            5.1 |           3.3 |            1.7 |           0.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  19 |   26 | Iris-setosa     |            5   |           3   |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  20 |   27 | Iris-setosa     |            5   |           3.4 |            1.6 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  21 |   43 | Iris-setosa     |            4.4 |           3.2 |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  22 |   44 | Iris-setosa     |            5   |           3.5 |            1.6 |           0.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  23 |   45 | Iris-setosa     |            5.1 |           3.8 |            1.9 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  24 |   46 | Iris-setosa     |            4.8 |           3   |            1.4 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  25 |   47 | Iris-setosa     |            5.1 |           3.8 |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  26 |   48 | Iris-setosa     |            4.6 |           3.2 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  27 |   49 | Iris-setosa     |            5.3 |           3.7 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  28 |   50 | Iris-setosa     |            5   |           3.3 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  29 |   52 | Iris-versicolor |            6.4 |           3.2 |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  30 |   53 | Iris-versicolor |            6.9 |           3.1 |           40   |          15   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  31 |   54 | Iris-versicolor |            5.5 |           2.3 |            4   |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  32 |   55 | Iris-versicolor |            6.5 |           2.8 |            4.6 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  33 |   56 | Iris-versicolor |            5.7 |           2.8 |            4.5 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  34 |   57 | Iris-versicolor |            6.3 |           3.3 |            4.7 |           1.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  35 |   58 | Iris-versicolor |            4.9 |           2.4 |            3.3 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  36 |   59 | Iris-versicolor |            6.6 |           2.9 |            4.6 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  37 |   61 | Iris-versicolor |            5   |           2   |            3.5 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  38 |   62 | Iris-versicolor |            5.9 |           3   |            4.2 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  39 |   63 | Iris-versicolor |            6   |           2.2 |            4   |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  40 |   64 | Iris-versicolor |            6.1 |           2.9 |            4.7 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  41 |   65 | Iris-versicolor |            5.6 |           2.9 |            3.6 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  42 |   66 | Iris-versicolor |            6.7 |           3.1 |            4.4 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  43 |   68 | Iris-versicolor |            5.8 |           2.7 |            4.1 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  44 |   69 | Iris-versicolor |            6.2 |           2.2 |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  45 |   70 | Iris-versicolor |            5.6 |           2.5 |            3.9 |           1.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  46 |   71 | Iris-versicolor |            5.9 |           3.2 |            4.8 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  47 |   72 | Iris-versicolor |            6.1 |           2.8 |            4   |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  48 |   73 | Iris-versicolor |            6.3 |           2.5 |            4.9 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  49 |   74 | Iris-versicolor |            6.1 |           2.8 |            4.7 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  50 |   75 | Iris-versicolor |            6.4 |           2.9 |            4.3 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  51 |   76 | Iris-versicolor |            6.6 |           3   |            4.4 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  52 |   77 | Iris-versicolor |            6.8 |           2.8 |            4.8 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  53 |   78 | Iris-versicolor |            6.7 |           3   |            5   |           1.7 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  54 |   80 | Iris-versicolor |            5.7 |           2.6 |            3.5 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  55 |   81 | Iris-versicolor |            5.5 |           2.4 |            3.8 |           1.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  56 |   83 | Iris-versicolor |            5.8 |           2.7 |            3.9 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  57 |   84 | Iris-versicolor |            6   |           2.7 |            5.1 |           1.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  58 |   85 | Iris-versicolor |            5.4 |           3   |            4.5 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  59 |   86 | Iris-versicolor |            6   |           3.4 |            4.5 |           1.6 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  60 |   87 | Iris-versicolor |            6.7 |           3.1 |            4.7 |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  61 |   88 | Iris-versicolor |            6.3 |           2.3 |            4.4 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  62 |   89 | Iris-versicolor |            5.6 |           3   |            4.1 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  63 |   90 | Iris-versicolor |            5.5 |           2.5 |            4   |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  64 |   91 | Iris-versicolor |            5.5 |           2.6 |            4.4 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  65 |   92 | Iris-versicolor |            6.1 |           3   |            4.6 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  66 |   93 | Iris-versicolor |            5.8 |           2.6 |            4   |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  67 |   94 | Iris-versicolor |            5   |           2.3 |            3.3 |           1   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  68 |   95 | Iris-versicolor |            5.6 |           2.7 |            4.2 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  69 |   96 | Iris-versicolor |            5.7 |           3   |            4.2 |           1.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  70 |   97 | Iris-versicolor |            5.7 |           2.9 |            4.2 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  71 |   98 | Iris-versicolor |            6.2 |           2.9 |            4.3 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  72 |   99 | Iris-versicolor |            5.1 |           2.5 |            3   |           1.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  73 |  100 | Iris-versicolor |            5.7 |           2.8 |            4.1 |           1.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  74 |  101 | Iris-virginica  |            6.3 |           3.3 |            6   |           2.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  75 |  102 | Iris-virginica  |            5.8 |           2.7 |            5.1 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  76 |  103 | Iris-virginica  |            7.1 |           3   |            5.9 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  77 |  104 | Iris-virginica  |            6.3 |           2.9 |            5.6 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  78 |  105 | Iris-virginica  |            6.5 |           3   |            5.8 |           2.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  79 |  107 | Iris-virginica  |            4.9 |           2.5 |            4.5 |           1.7 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  80 |  108 | Iris-virginica  |            7.3 |           2.9 |            6.3 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  81 |  109 | Iris-virginica  |            6.7 |           2.5 |            5.8 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  82 |  110 | Iris-virginica  |            7.2 |           3.6 |           61   |          25   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  83 |  111 | Iris-virginica  |            6.5 |           3.2 |            5.1 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  84 |  112 | Iris-virginica  |            6.4 |           2.7 |            5.3 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  85 |  113 | Iris-virginica  |            6.8 |           3   |            5.5 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  86 |  114 | Iris-virginica  |            5.7 |           2.5 |            5   |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  87 |  115 | Iris-virginica  |            5.8 |           2.8 |            5.1 |           2.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  88 |  116 | Iris-virginica  |            6.4 |           3.2 |            5.3 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  89 |  117 | Iris-virginica  |            6.5 |           3   |            5.5 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  90 |  119 | Iris-virginica  |            7.7 |           2.6 |            6.9 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  91 |  120 | Iris-virginica  |            6   |           2.2 |            5   |           1.5 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  92 |  121 | Iris-virginica  |            6.9 |           3.2 |            5.7 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  93 |  122 | Iris-virginica  |            5.6 |           2.8 |            4.9 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  94 |  123 | Iris-virginica  |            7.7 |           2.8 |            6.7 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  95 |  124 | Iris-virginica  |            6.3 |           2.7 |            4.9 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  96 |  125 | Iris-virginica  |            6.7 |           3.3 |            5.7 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  97 |  126 | Iris-virginica  |            7.2 |           3.2 |            6   |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  98 |  127 | Iris-virginica  |            6.2 |           2.8 |            4.8 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
|  99 |  128 | Iris-virginica  |            6.1 |           3   |           49   |          18   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 100 |  129 | Iris-virginica  |            6.4 |           2.8 |            5.6 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 101 |  131 | Iris-virginica  |            7.4 |           2.8 |            6.1 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 102 |  132 | Iris-virginica  |            7.9 |           3.8 |            6.4 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 103 |  134 | Iris-virginica  |            6.3 |           2.8 |           51   |          15   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 104 |  135 | Iris-virginica  |            6.1 |           2.6 |            5.6 |           1.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 105 |  136 | Iris-virginica  |            7.7 |           3   |            6.1 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 106 |  138 | Iris-virginica  |            6.4 |           3.1 |            5.5 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 107 |  139 | Iris-virginica  |            6   |           3   |           48   |          18   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 108 |  140 | Iris-virginica  |            6.9 |           3.1 |            5.4 |           2.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 109 |  141 | Iris-virginica  |            6.7 |           3.1 |            5.6 |           2.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 110 |  142 | Iris-virginica  |            6.9 |           3.1 |            5.1 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 111 |   28 | Iris-setosa     |            5.2 |           3.5 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 112 |   29 | Iris-setosa     |            5.2 |           4.3 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 113 |   30 | Iris-setosa     |            4.7 |           3.2 |            1.6 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 114 |   31 | Iris-setosa     |            4.7 |           3.1 |           16   |          12   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 115 |   32 | Iris-setosa     |            5.5 |           4.4 |            1.5 |           0.4 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 116 |   33 | Iris-setosa     |            5.2 |           4.2 |            1.5 |           0.1 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 117 |   34 | Iris-setosa     |            5.5 |           4.2 |            1.4 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 118 |   35 | Iris-setosa     |            4.9 |           4.1 |           15   |           7   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 119 |   37 | Iris-setosa     |            5.5 |           3.5 |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 120 |   38 | Iris-setosa     |            4.9 |           3.1 |           15   |           8   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 121 |   39 | Iris-setosa     |            4.4 |           3   |            1.3 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 122 |   41 | Iris-setosa     |            5   |           3.5 |            1.3 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 123 |   42 | Iris-setosa     |            4.5 |           2.3 |            1.3 |           0.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 124 |   11 | Iris-setosa     |            5.4 |           3.7 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 125 |   60 | Iris-versicolor |           52   |          27   |           39   |          14   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 126 |  130 | Iris-virginica  |           72   |          30   |           58   |          16   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 127 |  143 | Iris-virginica  |            5.8 |           2.7 |            5.1 |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 128 |  144 | Iris-virginica  |            6.8 |           3.2 |            5.9 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 129 |  146 | Iris-virginica  |            6.7 |           3   |            5.2 |           2.3 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 130 |  147 | Iris-virginica  |            6.3 |           2.5 |            5   |           1.9 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 131 |  148 | Iris-virginica  |            6.5 |           3   |            5.2 |           2   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 132 |  150 | Iris-virginica  |            5.9 |           3   |            5.1 |           1.8 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 133 |   40 | Iris-setosa     |            5.1 |           3.4 |            1.5 |           0.2 |
+-----+------+-----------------+----------------+---------------+----------------+---------------+
| 134 |  145 | Iris-virginica  |           67   |          33   |           57   |          25   |
+-----+------+-----------------+----------------+---------------+----------------+---------------+

==============================
Total Data Awal     : 150
Total Outlier       : 15
Total Data Bersih   : 135
==============================
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="membandingkan-akurasi">
<h2><strong>Membandingkan Akurasi</strong><a class="headerlink" href="#membandingkan-akurasi" title="Link to this heading">#</a></h2>
<section id="persiapan-data-dan-encoding-kelas">
<h3>✅ 1. Persiapan Data dan Encoding Kelas<a class="headerlink" href="#persiapan-data-dan-encoding-kelas" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Mengambil fitur utama: <strong>“petal length”</strong> dan <strong>“petal width”</strong> sebagai input (X).</p></li>
<li><p>Target klasifikasi diambil dari kolom <strong>“Class”</strong>.</p></li>
<li><p>Target dikonversi ke bentuk numerik menggunakan <strong>LabelEncoder()</strong> agar bisa diproses oleh algoritma KNN.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="membuat-dan-melatih-model-knn-tanpa-menghapus-outlier">
<h3>✅ 2. Membuat dan Melatih Model KNN (Tanpa Menghapus Outlier)<a class="headerlink" href="#membuat-dan-melatih-model-knn-tanpa-menghapus-outlier" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Dataset dibagi menjadi <strong>data latih (80%)</strong> dan <strong>data uji (20%)</strong> menggunakan <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code>.</p></li>
<li><p>Model menggunakan <strong>Pipeline</strong> yang terdiri dari:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code> untuk normalisasi data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier(n_neighbors=11)</span></code> sebagai algoritma KNN.</p></li>
</ul>
</li>
<li><p>Model dilatih dan diuji <strong>langsung</strong> menggunakan data <strong>yang masih mengandung outlier</strong>.</p></li>
<li><p>Evaluasi model dilakukan menggunakan:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">classification_report</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code></p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="deteksi-outlier-menggunakan-local-outlier-factor-lof">
<h3>✅ 3. Deteksi Outlier Menggunakan Local Outlier Factor (LOF)<a class="headerlink" href="#deteksi-outlier-menggunakan-local-outlier-factor-lof" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>LOF (Local Outlier Factor)</strong> digunakan untuk mendeteksi data yang dianggap outlier berdasarkan jarak dengan tetangga terdekatnya.</p></li>
<li><p>Parameter LOF:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">n_neighbors=20</span></code> : jumlah tetangga terdekat yang dihitung.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">contamination=0.1</span></code> : mengasumsikan sekitar 10% data adalah outlier.</p></li>
</ul>
</li>
<li><p>Hasil LOF:</p>
<ul>
<li><p>Label <code class="docutils literal notranslate"><span class="pre">-1</span></code> menunjukkan data <strong>outlier</strong>.</p></li>
<li><p>Label <code class="docutils literal notranslate"><span class="pre">1</span></code> menunjukkan data <strong>inlier</strong> atau data normal.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="membersihkan-data-dari-outlier">
<h3>✅ 4. Membersihkan Data dari Outlier<a class="headerlink" href="#membersihkan-data-dari-outlier" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Data yang terdeteksi sebagai <strong>outlier</strong> (label <code class="docutils literal notranslate"><span class="pre">-1</span></code>) dihapus dari dataset.</p></li>
<li><p>Hanya data <strong>inlier</strong> yang tersisa dan digunakan untuk proses pelatihan ulang model.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="melatih-ulang-model-knn-setelah-outlier-dihapus">
<h3>✅ 5. Melatih Ulang Model KNN Setelah Outlier Dihapus<a class="headerlink" href="#melatih-ulang-model-knn-setelah-outlier-dihapus" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Model KNN dilatih ulang dengan data <strong>yang sudah bersih (tanpa outlier)</strong>.</p></li>
<li><p>Proses training dan testing sama seperti model sebelumnya:</p>
<ul>
<li><p>Split data</p></li>
<li><p>Pipeline (StandardScaler + KNN)</p></li>
</ul>
</li>
<li><p>Model diuji ulang dan hasilnya dibandingkan.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="evaluasi-dan-perbandingan-hasil">
<h3>✅ 6. Evaluasi dan Perbandingan Hasil<a class="headerlink" href="#evaluasi-dan-perbandingan-hasil" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Menampilkan hasil evaluasi model <strong>sebelum</strong> dan <strong>sesudah</strong> outlier dihapus.</p></li>
<li><p>Evaluasi menggunakan:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">classification_report</span></code> (precision, recall, f1-score)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code></p></li>
</ul>
</li>
<li><p>Tujuan evaluasi:</p>
<ul>
<li><p>Melihat apakah <strong>menghapus outlier meningkatkan performa model</strong>.</p></li>
<li><p>Membuktikan bahwa <strong>outlier berpengaruh terhadap akurasi model</strong>.</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="kesimpulan">
<h3>📈 Kesimpulan:<a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Outlier</strong> dalam dataset bisa <strong>menurunkan akurasi model</strong> karena data tidak representatif.</p></li>
<li><p>Dengan menghapus outlier, model menjadi lebih <strong>stabil, akurat</strong>, dan <strong>mampu melakukan generalisasi</strong> lebih baik pada data baru.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>

<span class="c1"># Encode target class menjadi angka</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># 1. MODEL DENGAN OUTLIER</span>
<span class="n">X_train_ori</span><span class="p">,</span> <span class="n">X_test_ori</span><span class="p">,</span> <span class="n">y_train_ori</span><span class="p">,</span> <span class="n">y_test_ori</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">pipeline_ori</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">pipeline_ori</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_ori</span><span class="p">,</span> <span class="n">y_train_ori</span><span class="p">)</span>
<span class="n">y_pred_ori</span> <span class="o">=</span> <span class="n">pipeline_ori</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_ori</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> HASIL MODEL DENGAN OUTLIER :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_ori</span><span class="p">,</span> <span class="n">y_pred_ori</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_ori</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_ori</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 2. DETEKSI DAN HAPUS OUTLIER</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Tandai outlier</span>
<span class="n">df_combined</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Filter hanya data inlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_combined</span><span class="p">[</span><span class="n">df_combined</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># 3. MODEL SETELAH OUTLIER DIHAPUS</span>
<span class="n">X_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_clean</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">])</span>

<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_clean</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">pipeline_clean</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">pipeline_clean</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">pipeline_clean</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">HASIL MODEL SETELAH OUTLIER DIHAPUS :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_clean</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> HASIL MODEL DENGAN OUTLIER :
                 precision    recall  f1-score   support

    Iris-setosa       1.00      0.80      0.89        10
Iris-versicolor       1.00      0.92      0.96        12
 Iris-virginica       0.73      1.00      0.84         8

       accuracy                           0.90        30
      macro avg       0.91      0.91      0.90        30
   weighted avg       0.93      0.90      0.90        30

Akurasi: 0.9000

HASIL MODEL SETELAH OUTLIER DIHAPUS :
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        10
Iris-versicolor       0.90      0.90      0.90        10
 Iris-virginica       0.86      0.86      0.86         7

       accuracy                           0.93        27
      macro avg       0.92      0.92      0.92        27
   weighted avg       0.93      0.93      0.93        27

Akurasi: 0.9259
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Data_Understanding.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Data Understanding</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="LOF.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Local Outlier Factor (LOF)</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier-menggunakan-algoritma-k-nn"><strong>Deteksi Outlier Menggunakan Algoritma K-NN</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contoh-deteksi-manual-outlier-dengan-k-nn-suhu"><strong>Contoh Deteksi Manual Outlier dengan K-NN (Suhu)</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data"><strong>Data</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-deteksi-outlier"><strong>Langkah-Langkah Deteksi Outlier</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hitung-jarak-antar-titik"><strong>1. Hitung Jarak Antar Titik</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menentukan-outlier"><strong>2. Menentukan Outlier</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hitung-rata-rata-jarak-ke-k-tetangga-terdekat"><strong>3. Hitung Rata-rata jarak ke K tetangga terdekat</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>1. Hitung Jarak Antar Titik</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2"><strong>2. Menentukan Outlier</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3"><strong>3. Hitung Rata-rata jarak ke K tetangga terdekat</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-mendeteksi-outlier-dengan-algoritma-k-nn-dengan-code"><strong>Langkah-langkah Mendeteksi Outlier Dengan Algoritma K-NN Dengan Code</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cek-koneksi-database-mysql">Cek koneksi Database MySQL</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cek-koneksi-database-postgresql">Cek koneksi Database PostgreSQL</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#merging-data"><strong>MERGING DATA</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-deteksi-outlier-dengan-algoritma-k-nn-euclidean-distance">Code Deteksi Outlier dengan Algoritma K-NN - Euclidean Distance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mencari-data-yang-diduga-outlier-menggunakan-localoutlierfactor"><strong>Mencari Data yang Diduga Outlier (menggunakan LocalOutlierFactor):</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fungsi-kode"><strong>Fungsi Kode</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mencari-data-yang-diduga-outlier-menggunakan-euclidean-distance"><strong>Mencari Data yang Diduga Outlier (menggunakan Euclidean Distance):</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-singkat-kode"><strong>Penjelasan Singkat Kode</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-bersih-dari-outlier"><strong>Data Bersih dari Outlier</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Penjelasan Singkat Kode</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#membandingkan-akurasi"><strong>Membandingkan Akurasi</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#persiapan-data-dan-encoding-kelas">✅ 1. Persiapan Data dan Encoding Kelas</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membuat-dan-melatih-model-knn-tanpa-menghapus-outlier">✅ 2. Membuat dan Melatih Model KNN (Tanpa Menghapus Outlier)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier-menggunakan-local-outlier-factor-lof">✅ 3. Deteksi Outlier Menggunakan Local Outlier Factor (LOF)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membersihkan-data-dari-outlier">✅ 4. Membersihkan Data dari Outlier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#melatih-ulang-model-knn-setelah-outlier-dihapus">✅ 5. Melatih Ulang Model KNN Setelah Outlier Dihapus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-dan-perbandingan-hasil">✅ 6. Evaluasi dan Perbandingan Hasil</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">📈 Kesimpulan:</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Muhammad Ilham Adila Almafaz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>